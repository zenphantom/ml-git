{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes a basic flow with ml-git. In it, we will show how to obtain a dataset already versioned by ml-git, how to perform a versioning process of a model and new data generated. For this, we will use the MNIST dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset MNIST is a set of small images of handwritten digits, in the version available in our docker environment, the set has a total of 70,000 images from numbers 0 to 9. Look at the below image which has a few examples instances:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset](MNIST.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start working with our dataset it is necessary to carry out the checkout command of ml-git in order to bring the data from our storage to the user's workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ml-git labels checkout labelsmnist -d\n",
    "mnist_dataset_path = 'datasets/handwritten/digits/mnist/data/'\n",
    "mnist_labels_path = 'labels/handwritten/digits/labelsmnist/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important points to highlight here are that the tag parameter can be the name of the entity, this way the ml-git will get the latest version available for this entity. With the -d signals that ml-git should look for the dataset associated with these labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the data in the workspace, we can load it into variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "X_train = pickle.load(open(mnist_dataset_path + 'train-images.idx3-ubyte', 'rb' ))\n",
    "y_train = pickle.load(open(mnist_labels_path + 'train-labels.idx1-ubyte', 'rb' ))\n",
    "\n",
    "print('Training data: ')\n",
    "print('Dimensions: %s x %s' % (X_train.shape[0], X_train.shape[1]))\n",
    "print('Digits: %s' % np.unique(y_train))\n",
    "print('Class distribution: %s' % np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data consists of 60,000 entries of 784 pixels, distributed among the possible values ​​according to the output above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = loadlocal_mnist(\n",
    "    images_path= mnist_dataset_path + 't10k-images.idx3-ubyte', \n",
    "    labels_path= mnist_labels_path + 't10k-labels.idx1-ubyte')\n",
    "\n",
    "print('Test data: ')\n",
    "print('Dimensions: %s x %s' % (X_test.shape[0], X_test.shape[1]))\n",
    "print('Digits: %s' % np.unique(y_test))\n",
    "print('Class distribution: %s' % np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data consists of 10,000 entries of 784 pixels, distributed among the possible values according to the output above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Training and evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take an example of RandomForest Classifier and train it on the dataset and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Training on the existing dataset\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy score after training on existing dataset', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Versioning our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we do not have any previously versioned models, it will be necessary to create a new entity. For this we use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ml-git models create modelmnist --category=handwritten --category=digits --bucket-name=mlgit --mutability=mutable --entity-dir='handwritten/digits'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our model trained and evaluated, we will version it with ml-git. For that we need to save it in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model):\n",
    "    filename = 'models/handwritten/digits/modelmnist/data/rf_mnist.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "save_model(rf_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the file in the workspace we use the following commands to create a version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ml-git models add modelmnist --metric accuracy $score\n",
    "! ml-git models commit modelmnist --dataset=mnist --labels=labelsmnist\n",
    "! ml-git models push modelmnist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Adding new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point after training a model it may be the case that new data is available.\n",
    "\n",
    "It is interesting that this new data is added to our entity to generate a second version of our dataset.\n",
    "\n",
    "Let's add this data to our entity's directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! cp train-images.idx3-ubyte dataset/handwritten/digits/mnist/data/.\n",
    "! cp train-labels.idx1-ubyte labels/handwritten/digits/labelsmnist/data/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Let's take a look at our new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the dataset\n",
    "X_train = pickle.load(open(mnist_dataset_path + 'train-images.idx3-ubyte', 'rb' ))\n",
    "y_train = pickle.load(open(mnist_labels_path + 'train-labels.idx1-ubyte', 'rb' ))\n",
    "\n",
    "print('Test data: ')\n",
    "print('Dimensions: %s x %s' % (X_train.shape[0], X_train.shape[1]))\n",
    "print('Digits: %s' % np.unique(y_train))\n",
    "print('Class distribution: %s' % np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train data now consists of 180,000 entries of 784 pixels, distributed among the possible values according to the output above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Versioning the dataset and labels with the new entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_file = 'datasets/handwritten/digits/mnist/data/train-images.idx3-ubyte'\n",
    "pickle.dump(X_train, open(dataset_file, 'wb'))\n",
    "\n",
    "labels_file = 'labels/handwritten/digits/labelsmnist/data/train-labels.idx1-ubyte'\n",
    "pickle.dump(y_train, open(labels_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versioning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ml-git datasets add mnist --bumpversion\n",
    "! ml-git datasets commit mnist \n",
    "! ml-git datasets push mnist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versioning the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ml-git labels add labelsmnist --bumpversion\n",
    "! ml-git labels commit labelsmnist --dataset=mnist\n",
    "! ml-git labels push labelsmnist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Training and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on new data\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy score after training on augmented dataset\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve improved the accuracy by ~0.4%. This is great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Versioning our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(rf_clf)\n",
    "\n",
    "! ml-git models add modelmnist --bumpversion --metric accuracy $score\n",
    "! ml-git models commit modelmnist --dataset=mnist --labels=labelsmnist\n",
    "! ml-git models push modelmnist "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:blue\"> 9 - Reproducing our experiment with ml-git</span> \n",
    "\n",
    "\n",
    "Once the experiment data is versioned, it is common that it is necessary to re-evaluate the result, or that someone else wants to see the result of an already trained model.\n",
    "\n",
    "For this, we will perform the model checkout in version 1, to get the test data and the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset_path = 'datasets/handwritten/digits/mnist/data/'\n",
    "mnist_labels_path = 'labels/handwritten/digits/labelsmnist/data/'\n",
    "mnist_model_path = 'models/handwritten/digits/modelmnist/data/'\n",
    "\n",
    "! ml-git models checkout handwritten__digits__modelmnist__1 -d -l\n",
    "\n",
    "# Getting test data\n",
    "X_test, y_test = loadlocal_mnist(images_path= mnist_dataset_path + 't10k-images.idx3-ubyte', \n",
    "                                 labels_path= mnist_labels_path + 't10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the test data in hand, let's upload the model and evaluate it for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = pickle.load(open(mnist_model_path + 'rf_mnist.sav', 'rb'))\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy score for version 1: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the model from the version 2 (model trained with more data) and evaluate it for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ml-git models checkout handwritten__digits__modelmnist__2\n",
    "loaded_model = pickle.load(open(mnist_model_path + 'rf_mnist.sav', 'rb'))\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy score for version 2: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a quick and practical way it was possible to obtain the models generated in the experiments and to evaluate them again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this execution we have two versions of each entity. If someone else wants to replicate this experiment, they can check out the model with the related dataset and labels."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "source": [
    "! ml-git models metrics model-ex"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
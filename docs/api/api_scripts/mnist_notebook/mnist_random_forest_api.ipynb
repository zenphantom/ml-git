{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML-Git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook describes a basic execution flow of ml-git with its API. In it, we show how to obtain a dataset already versioned by ml-git, how to perform the versioning process of a model and the new data generated, using the MNIST dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook state management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have already run this notebook or another notebook in this same folder, it is recommended that you execute the cell below to clean the environment, as state changes made previously may interfere with the notebook running. Be aware that this procedure does not affect any remote repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sh ./clean_environment.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 - The dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset MNIST is a set of small images of handwritten digits, in the version available in our docker environment, the set has a total of 70,000 images from numbers 0 to 9. Look at the below image which has a few examples instances:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![dataset](MNIST.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 - Getting the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start working with our dataset it is necessary to carry out the checkout command of ml-git in order to bring the data from our storage to the user's workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Metadata Manager: Pull [/api_scripts/mnist_notebook/.ml-git/labels/metadata]\n",
      "INFO - Metadata: Performing checkout on the entity's lastest tag (handwritten__digits__labelsmnist__1)\n",
      "blobs: 100%|██████████| 2.00/2.00 [00:00<00:00, 184blobs/s]\n",
      "chunks: 100%|██████████| 2.00/2.00 [00:00<00:00, 206chunks/s]\n",
      "files into workspace: 100%|██████████| 2.00/2.00 [00:00<00:00, 885files into workspace/s]\n",
      "INFO - Repository: Initializing related datasets download\n",
      "blobs: 100%|██████████| 2.00/2.00 [00:00<00:00, 226blobs/s]\n",
      "chunks: 100%|██████████| 2.00/2.00 [00:00<00:00, 2.24chunks/s]\n",
      "files into workspace: 100%|██████████| 2.00/2.00 [00:00<00:00, 13.2files into workspace/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "from ml_git.api import MLGitAPI\n",
    "api = MLGitAPI()\n",
    "\n",
    "# def checkout(entity, tag, sampling=None, retries=2, force=False, dataset=False, labels=False, version=-1)\n",
    "api.checkout('labels', 'labelsmnist', dataset=True)\n",
    "mnist_dataset_path = 'datasets/handwritten/digits/mnist/data/'\n",
    "mnist_labels_path = 'labels/handwritten/digits/labelsmnist/data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some important points to highlight here are that the tag parameter can be the name of the entity, this way the ml-git will get the latest version available for this entity. With the dataset=True signals that ml-git should look for the dataset associated with these labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have the data in the workspace, we can load it into variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: \n",
      "Dimensions: 60000 x 784\n",
      "Digits: [0 1 2 3 4 5 6 7 8 9]\n",
      "Class distribution: [5923 6742 5958 6131 5842 5421 5918 6265 5851 5949]\n",
      "\r"
     ]
    }
   ],
   "source": [
    "from mlxtend.data import loadlocal_mnist\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "X_train = pickle.load(open(mnist_dataset_path + 'train-images.idx3-ubyte', 'rb' ))\n",
    "y_train = pickle.load(open(mnist_labels_path + 'train-labels.idx1-ubyte', 'rb' ))\n",
    "\n",
    "print('Training data: ')\n",
    "print('Dimensions: %s x %s' % (X_train.shape[0], X_train.shape[1]))\n",
    "print('Digits: %s' % np.unique(y_train))\n",
    "print('Class distribution: %s' % np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data consists of 60,000 entries of 784 pixels, distributed among the possible values ​​according to the output above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: \n",
      "Dimensions: 10000 x 784\n",
      "Digits: [0 1 2 3 4 5 6 7 8 9]\n",
      "Class distribution: [ 980 1135 1032 1010  982  892  958 1028  974 1009]\n",
      "\r"
     ]
    }
   ],
   "source": [
    "X_test, y_test = loadlocal_mnist(\n",
    "    images_path= mnist_dataset_path + 't10k-images.idx3-ubyte', \n",
    "    labels_path= mnist_labels_path + 't10k-labels.idx1-ubyte')\n",
    "\n",
    "print('Test data: ')\n",
    "print('Dimensions: %s x %s' % (X_test.shape[0], X_test.shape[1]))\n",
    "print('Digits: %s' % np.unique(y_test))\n",
    "print('Class distribution: %s' % np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test data consists of 10,000 entries of 784 pixels, distributed among the possible values according to the output above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 - Training and evaluating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s take an example of RandomForest Classifier and train it on the dataset and evaluate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score after training on existing dataset 0.9705\n",
      "\r"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Training on the existing dataset\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy score after training on existing dataset', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 - Versioning our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we do not have any previously versioned models, it will be necessary to create a new entity. For this we use the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - MLGit: Model artifact created.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# def create(entity, entity_name, categories, mutability, **kwargs)\n",
    "api.create('models', 'modelmnist', categories=['handwritten', 'digits'], mutability='mutable', bucket_name='mlgit', entity_dir='handwritten/digits')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have our model trained and evaluated, we will version it with ml-git. For that we need to save it in a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "def save_model(model):\n",
    "    filename = 'models/handwritten/digits/modelmnist/data/rf_mnist.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "\n",
    "save_model(rf_clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the file in the workspace we use the following commands to create a version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Metadata Manager: Pull [/api_scripts/mnist_notebook/.ml-git/models/metadata]\n",
      "INFO - Repository: models adding path [/api_scripts/mnist_notebook/models/handwritten/digits/modelmnist] to ml-git index\n",
      "files: 100%|██████████| 1.00/1.00 [00:00<00:00, 1.56files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Creating hard links in cache⠙ Creating hard links in cache\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "files: 100%|██████████| 1.00/1.00 [00:00<00:00, 7.13kfiles/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Updating index⠙ Updating index Checking removed files⠙ Checking removed files Commit manifest⠙ Commit manifest\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Local Repository: Associate datasets [mnist]-[handwritten__digits__mnist__1] to the models.\n",
      "INFO - Local Repository: Associate labels [labelsmnist]-[handwritten__digits__labelsmnist__1] to the models.\n",
      "INFO - Metadata Manager: Commit repo[/api_scripts/mnist_notebook/.ml-git/models/metadata] --- file[handwritten/digits/modelmnist]\n",
      "files: 100%|██████████| 520/520 [00:06<00:00, 82.0files/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Pushing metadata to the git repository⠙ Pushing metadata to the git repository"
     ]
    }
   ],
   "source": [
    "entity_type = 'models'\n",
    "entity_name = 'modelmnist'\n",
    "\n",
    "# def add(entity_type, entity_name, bumpversion=False, fsck=False, file_path=[])\n",
    "api.add(entity_type, entity_name, metric={'accuracy': score})\n",
    "\n",
    "# def commit(entity, ml_entity_name, commit_message=None, related_dataset=None, related_labels=None)\n",
    "api.commit(entity_type, entity_name, related_dataset='mnist', related_labels='labelsmnist')\n",
    "\n",
    "# def push(entity, entity_name, retries=2, clear_on_fail=False)\n",
    "api.push(entity_type, entity_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 - Adding new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At some point after training a model it may be the case that new data is available.\n",
    "\n",
    "It is interesting that this new data is added to our entity to generate a second version of our dataset.\n",
    "\n",
    "Let's add this data to our entity's directory:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "! cp train-images.idx3-ubyte datasets/handwritten/digits/mnist/data/.\n",
    "! cp train-labels.idx1-ubyte labels/handwritten/digits/labelsmnist/data/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at our new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data: \n",
      "Dimensions: 180000 x 784\n",
      "Digits: [0 1 2 3 4 5 6 7 8 9]\n",
      "Class distribution: [17769 20226 17874 18393 17526 16263 17754 18795 17553 17847]\n",
      "\r"
     ]
    }
   ],
   "source": [
    "# loading the dataset\n",
    "X_train = pickle.load(open(mnist_dataset_path + 'train-images.idx3-ubyte', 'rb' ))\n",
    "y_train = pickle.load(open(mnist_labels_path + 'train-labels.idx1-ubyte', 'rb' ))\n",
    "\n",
    "print('Test data: ')\n",
    "print('Dimensions: %s x %s' % (X_train.shape[0], X_train.shape[1]))\n",
    "print('Digits: %s' % np.unique(y_train))\n",
    "print('Class distribution: %s' % np.bincount(y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train data now consists of 180,000 entries of 784 pixels, distributed among the possible values according to the output above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 - Versioning the dataset and labels with the new entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "dataset_file = 'datasets/handwritten/digits/mnist/data/train-images.idx3-ubyte'\n",
    "pickle.dump(X_train, open(dataset_file, 'wb'))\n",
    "\n",
    "labels_file = 'labels/handwritten/digits/labelsmnist/data/train-labels.idx1-ubyte'\n",
    "pickle.dump(y_train, open(labels_file, 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versioning the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Metadata Manager: Pull [/api_scripts/mnist_notebook/.ml-git/datasets/metadata]\n",
      "INFO - Repository: datasets adding path [/api_scripts/mnist_notebook/datasets/handwritten/digits/mnist] to ml-git index\n",
      "files: 100%|██████████| 2.00/2.00 [00:05<00:00, 2.63s/files]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'zdj7WmvrKwjWMCQMFFgcMFmGxEgQS2uXatYWxcE3ByNJeDmze'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Creating hard links in cache⠙ Creating hard links in cache\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "files: 100%|██████████| 2.00/2.00 [00:00<00:00, 2.24kfiles/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Updating index⠙ Updating index Checking removed files⠙ Checking removed files Commit manifest⠙ Commit manifest\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Metadata Manager: Commit repo[/api_scripts/mnist_notebook/.ml-git/datasets/metadata] --- file[handwritten/digits/mnist]\n",
      "files: 100%|██████████| 540/540 [00:17<00:00, 31.0files/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Pushing metadata to the git repository⠙ Pushing metadata to the git repository"
     ]
    }
   ],
   "source": [
    "entity_type = 'datasets'\n",
    "entity_name = 'mnist'\n",
    "\n",
    "api.add(entity_type, entity_name, bumpversion=True)\n",
    "api.commit(entity_type, entity_name)\n",
    "api.push(entity_type, entity_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Versioning the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Metadata Manager: Pull [/api_scripts/mnist_notebook/.ml-git/labels/metadata]\n",
      "INFO - Repository: labels adding path [/api_scripts/mnist_notebook/labels/handwritten/digits/labelsmnist] to ml-git index\n",
      "files: 0.00files [00:00, ?files/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'zdj7WaeJerH7ACFKfFgh9itrCoWt3iBCYagzYS2M7VhidBAmR'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "files: 100%|██████████| 2.00/2.00 [00:00<00:00, 227files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Creating hard links in cache⠙ Creating hard links in cache\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "files: 100%|██████████| 2.00/2.00 [00:00<00:00, 8.93kfiles/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Updating index⠙ Updating index Checking removed files⠙ Checking removed files Commit manifest⠙ Commit manifest\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Local Repository: Associate datasets [mnist]-[handwritten__digits__mnist__2] to the labels.\n",
      "INFO - Metadata Manager: Commit repo[/api_scripts/mnist_notebook/.ml-git/labels/metadata] --- file[handwritten/digits/labelsmnist]\n",
      "files: 100%|██████████| 2.00/2.00 [00:00<00:00, 71.8files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Pushing metadata to the git repository⠙ Pushing metadata to the git repository"
     ]
    }
   ],
   "source": [
    "entity_type = 'labels'\n",
    "entity_name = 'labelsmnist'\n",
    "\n",
    "api.add(entity_type, entity_name, bumpversion=True)\n",
    "api.commit(entity_type, entity_name, related_dataset='mnist')\n",
    "api.push(entity_type, entity_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7 - Training and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score after training on augmented dataset 0.9746\n",
      "\r"
     ]
    }
   ],
   "source": [
    "# Training on new data\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "# Evaluating the model\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy score after training on augmented dataset\", score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We’ve improved the accuracy by ~0.4%. This is great."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8 - Versioning our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Metadata Manager: Pull [/api_scripts/mnist_notebook/.ml-git/models/metadata]\n",
      "INFO - Repository: models adding path [/api_scripts/mnist_notebook/models/handwritten/digits/modelmnist] to ml-git index\n",
      "files: 100%|██████████| 1.00/1.00 [00:04<00:00, 4.46s/files]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'zdj7WfjwEm3XVzoggyG1kSPQhYMSMpbBdLzYMx5Z61StSbu5H'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Creating hard links in cache⠙ Creating hard links in cache\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "files: 100%|██████████| 1.00/1.00 [00:00<00:00, 6.36kfiles/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Updating index⠙ Updating index Checking removed files⠙ Checking removed files Commit manifest⠙ Commit manifest\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Local Repository: Associate datasets [mnist]-[handwritten__digits__mnist__2] to the models.\n",
      "INFO - Local Repository: Associate labels [labelsmnist]-[handwritten__digits__labelsmnist__2] to the models.\n",
      "INFO - Metadata Manager: Commit repo[/api_scripts/mnist_notebook/.ml-git/models/metadata] --- file[handwritten/digits/modelmnist]\n",
      "files: 100%|██████████| 1.39k/1.39k [00:22<00:00, 62.1files/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⠋ Pushing metadata to the git repository⠙ Pushing metadata to the git repository⠹ Pushing metadata to the git repository"
     ]
    }
   ],
   "source": [
    "save_model(rf_clf)\n",
    "\n",
    "entity_type = 'models'\n",
    "entity_name = 'modelmnist'\n",
    "\n",
    "api.add(entity_type, entity_name, bumpversion=True, metric={'accuracy': score})\n",
    "api.commit(entity_type, entity_name, related_dataset='mnist', related_labels='labelsmnist')\n",
    "api.push(entity_type, entity_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  <span style=\"color:blue\"> 9 - Reproducing our experiment with ml-git</span> \n",
    "\n",
    "\n",
    "Once the experiment data is versioned, it is common that it is necessary to re-evaluate the result, or that someone else wants to see the result of an already trained model.\n",
    "\n",
    "For this, we will perform the model checkout in version 1 (without the data augmentation), to get the test data and the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Metadata Manager: Pull [/api_scripts/mnist_notebook/.ml-git/models/metadata]\n",
      "blobs: 100%|██████████| 1.00/1.00 [00:00<00:00, 95.1blobs/s]\n",
      "chunks: 100%|██████████| 1.00/1.00 [00:00<00:00, 3.44chunks/s]\n",
      "files into workspace: 100%|██████████| 1.00/1.00 [00:14<00:00, 14.1s/files into workspace]\n",
      "INFO - Repository: Initializing related datasets download\n",
      "blobs: 100%|██████████| 2.00/2.00 [00:00<00:00, 228blobs/s]\n",
      "chunks: 100%|██████████| 2.00/2.00 [00:00<00:00, 20.6chunks/s]\n",
      "files into workspace: 100%|██████████| 2.00/2.00 [00:04<00:00, 2.15s/files into workspace]\n",
      "INFO - Repository: Initializing related labels download\n",
      "blobs: 100%|██████████| 2.00/2.00 [00:00<00:00, 810blobs/s]\n",
      "chunks: 100%|██████████| 2.00/2.00 [00:00<00:00, 234chunks/s]\n",
      "files into workspace: 100%|██████████| 2.00/2.00 [00:00<00:00, 761files into workspace/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "mnist_dataset_path = 'datasets/handwritten/digits/mnist/data/'\n",
    "mnist_labels_path = 'labels/handwritten/digits/labelsmnist/data/'\n",
    "mnist_model_path = 'models/handwritten/digits/modelmnist/data/'\n",
    "\n",
    "api.checkout('models', 'handwritten__digits__modelmnist__1', dataset=True, labels=True)\n",
    "\n",
    "# Getting test data\n",
    "X_test, y_test = loadlocal_mnist(images_path= mnist_dataset_path + 't10k-images.idx3-ubyte', \n",
    "                                 labels_path= mnist_labels_path + 't10k-labels.idx1-ubyte')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the test data in hand, let's upload the model and evaluate it for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for version 1:  0.9705\n",
      "\r"
     ]
    }
   ],
   "source": [
    "loaded_model = pickle.load(open(mnist_model_path + 'rf_mnist.sav', 'rb'))\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy score for version 1: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take the model from the version 2 (model trained with more data) and evaluate it for the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Metadata Manager: Pull [/api_scripts/mnist_notebook/.ml-git/models/metadata]\n",
      "blobs: 100%|██████████| 1.00/1.00 [00:00<00:00, 1.96kblobs/s]\n",
      "chunks: 100%|██████████| 1.00/1.00 [00:00<00:00, 18.4chunks/s]\n",
      "files into workspace: 100%|██████████| 1.00/1.00 [00:05<00:00, 5.36s/files into workspace]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for version 2:  0.9746\n",
      "\r"
     ]
    }
   ],
   "source": [
    "api.checkout('models', 'handwritten__digits__modelmnist__2')\n",
    "loaded_model = pickle.load(open(mnist_model_path + 'rf_mnist.sav', 'rb'))\n",
    "y_pred = loaded_model.predict(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy score for version 2: ', score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a quick and practical way it was possible to obtain the models generated in the experiments and to evaluate them again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At the end of this execution we have two versions of each entity. If someone else wants to replicate this experiment, they can check out the model with the related dataset and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Tag</th>\n",
       "      <th>Related dataset - (version)</th>\n",
       "      <th>Related labels - (version)</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-03-25 14:52:42</td>\n",
       "      <td>handwritten__digits__modelmnist__1</td>\n",
       "      <td>mnist - (1)</td>\n",
       "      <td>labelsmnist - (1)</td>\n",
       "      <td>0.9705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-03-25 14:55:52</td>\n",
       "      <td>handwritten__digits__modelmnist__2</td>\n",
       "      <td>mnist - (2)</td>\n",
       "      <td>labelsmnist - (2)</td>\n",
       "      <td>0.9746</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Date                                 Tag  \\\n",
       "0  2021-03-25 14:52:42  handwritten__digits__modelmnist__1   \n",
       "1  2021-03-25 14:55:52  handwritten__digits__modelmnist__2   \n",
       "\n",
       "  Related dataset - (version) Related labels - (version)  accuracy  \n",
       "0                 mnist - (1)          labelsmnist - (1)    0.9705  \n",
       "1                 mnist - (2)          labelsmnist - (2)    0.9746  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "info_data = api.get_models_metrics('modelmnist', export_type='csv')\n",
    "\n",
    "import pandas as pd\n",
    "info_table = pd.read_csv(info_data)\n",
    "\n",
    "# Displays whole table\n",
    "info_table"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}